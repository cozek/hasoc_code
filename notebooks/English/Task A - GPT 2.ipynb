{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Task A - GPT 2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njzRjFbiQYlu",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cozek/hasoc_code/blob/master/notebooks/English/Task%20A%20-%20GPT%202.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF2qyeioUpoh",
        "colab_type": "text"
      },
      "source": [
        "# Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw7CyHbUQVsr",
        "colab_type": "code",
        "outputId": "22cdd12b-e945-49f6-fe4d-98237b04f0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!rm -rf /content/hasoc_code/\n",
        "!git clone --recurse-submodules https://github.com/cozek/hasoc_code"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hasoc_code'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/79)\u001b[K\rremote: Counting objects:   2% (2/79)\u001b[K\rremote: Counting objects:   3% (3/79)\u001b[K\rremote: Counting objects:   5% (4/79)\u001b[K\rremote: Counting objects:   6% (5/79)\u001b[K\rremote: Counting objects:   7% (6/79)\u001b[K\rremote: Counting objects:   8% (7/79)\u001b[K\rremote: Counting objects:  10% (8/79)\u001b[K\rremote: Counting objects:  11% (9/79)\u001b[K\rremote: Counting objects:  12% (10/79)\u001b[K\rremote: Counting objects:  13% (11/79)\u001b[K\rremote: Counting objects:  15% (12/79)\u001b[K\rremote: Counting objects:  16% (13/79)\u001b[K\rremote: Counting objects:  17% (14/79)\u001b[K\rremote: Counting objects:  18% (15/79)\u001b[K\rremote: Counting objects:  20% (16/79)\u001b[K\rremote: Counting objects:  21% (17/79)\u001b[K\rremote: Counting objects:  22% (18/79)\u001b[K\rremote: Counting objects:  24% (19/79)\u001b[K\rremote: Counting objects:  25% (20/79)\u001b[K\rremote: Counting objects:  26% (21/79)\u001b[K\rremote: Counting objects:  27% (22/79)\u001b[K\rremote: Counting objects:  29% (23/79)\u001b[K\rremote: Counting objects:  30% (24/79)\u001b[K\rremote: Counting objects:  31% (25/79)\u001b[K\rremote: Counting objects:  32% (26/79)\u001b[K\rremote: Counting objects:  34% (27/79)\u001b[K\rremote: Counting objects:  35% (28/79)\u001b[K\rremote: Counting objects:  36% (29/79)\u001b[K\rremote: Counting objects:  37% (30/79)\u001b[K\rremote: Counting objects:  39% (31/79)\u001b[K\rremote: Counting objects:  40% (32/79)\u001b[K\rremote: Counting objects:  41% (33/79)\u001b[K\rremote: Counting objects:  43% (34/79)\u001b[K\rremote: Counting objects:  44% (35/79)\u001b[K\rremote: Counting objects:  45% (36/79)\u001b[K\rremote: Counting objects:  46% (37/79)\u001b[K\rremote: Counting objects:  48% (38/79)\u001b[K\rremote: Counting objects:  49% (39/79)\u001b[K\rremote: Counting objects:  50% (40/79)\u001b[K\rremote: Counting objects:  51% (41/79)\u001b[K\rremote: Counting objects:  53% (42/79)\u001b[K\rremote: Counting objects:  54% (43/79)\u001b[K\rremote: Counting objects:  55% (44/79)\u001b[K\rremote: Counting objects:  56% (45/79)\u001b[K\rremote: Counting objects:  58% (46/79)\u001b[K\rremote: Counting objects:  59% (47/79)\u001b[K\rremote: Counting objects:  60% (48/79)\u001b[K\rremote: Counting objects:  62% (49/79)\u001b[K\rremote: Counting objects:  63% (50/79)\u001b[K\rremote: Counting objects:  64% (51/79)\u001b[K\rremote: Counting objects:  65% (52/79)\u001b[K\rremote: Counting objects:  67% (53/79)\u001b[K\rremote: Counting objects:  68% (54/79)\u001b[K\rremote: Counting objects:  69% (55/79)\u001b[K\rremote: Counting objects:  70% (56/79)\u001b[K\rremote: Counting objects:  72% (57/79)\u001b[K\rremote: Counting objects:  73% (58/79)\u001b[K\rremote: Counting objects:  74% (59/79)\u001b[K\rremote: Counting objects:  75% (60/79)\u001b[K\rremote: Counting objects:  77% (61/79)\u001b[K\rremote: Counting objects:  78% (62/79)\u001b[K\rremote: Counting objects:  79% (63/79)\u001b[K\rremote: Counting objects:  81% (64/79)\u001b[K\rremote: Counting objects:  82% (65/79)\u001b[K\rremote: Counting objects:  83% (66/79)\u001b[K\rremote: Counting objects:  84% (67/79)\u001b[K\rremote: Counting objects:  86% (68/79)\u001b[K\rremote: Counting objects:  87% (69/79)\u001b[K\rremote: Counting objects:  88% (70/79)\u001b[K\rremote: Counting objects:  89% (71/79)\u001b[K\rremote: Counting objects:  91% (72/79)\u001b[K\rremote: Counting objects:  92% (73/79)\u001b[K\rremote: Counting objects:  93% (74/79)\u001b[K\rremote: Counting objects:  94% (75/79)\u001b[K\rremote: Counting objects:  96% (76/79)\u001b[K\rremote: Counting objects:  97% (77/79)\u001b[K\rremote: Counting objects:  98% (78/79)\u001b[K\rremote: Counting objects: 100% (79/79)\u001b[K\rremote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/58)\u001b[K\rremote: Compressing objects:   3% (2/58)\u001b[K\rremote: Compressing objects:   5% (3/58)\u001b[K\rremote: Compressing objects:   6% (4/58)\u001b[K\rremote: Compressing objects:   8% (5/58)\u001b[K\rremote: Compressing objects:  10% (6/58)\u001b[K\rremote: Compressing objects:  12% (7/58)\u001b[K\rremote: Compressing objects:  13% (8/58)\u001b[K\rremote: Compressing objects:  15% (9/58)\u001b[K\rremote: Compressing objects:  17% (10/58)\u001b[K\rremote: Compressing objects:  18% (11/58)\u001b[K\rremote: Compressing objects:  20% (12/58)\u001b[K\rremote: Compressing objects:  22% (13/58)\u001b[K\rremote: Compressing objects:  24% (14/58)\u001b[K\rremote: Compressing objects:  25% (15/58)\u001b[K\rremote: Compressing objects:  27% (16/58)\u001b[K\rremote: Compressing objects:  29% (17/58)\u001b[K\rremote: Compressing objects:  31% (18/58)\u001b[K\rremote: Compressing objects:  32% (19/58)\u001b[K\rremote: Compressing objects:  34% (20/58)\u001b[K\rremote: Compressing objects:  36% (21/58)\u001b[K\rremote: Compressing objects:  37% (22/58)\u001b[K\rremote: Compressing objects:  39% (23/58)\u001b[K\rremote: Compressing objects:  41% (24/58)\u001b[K\rremote: Compressing objects:  43% (25/58)\u001b[K\rremote: Compressing objects:  44% (26/58)\u001b[K\rremote: Compressing objects:  46% (27/58)\u001b[K\rremote: Compressing objects:  48% (28/58)\u001b[K\rremote: Compressing objects:  50% (29/58)\u001b[K\rremote: Compressing objects:  51% (30/58)\u001b[K\rremote: Compressing objects:  53% (31/58)\u001b[K\rremote: Compressing objects:  55% (32/58)\u001b[K\rremote: Compressing objects:  56% (33/58)\u001b[K\rremote: Compressing objects:  58% (34/58)\u001b[K\rremote: Compressing objects:  60% (35/58)\u001b[K\rremote: Compressing objects:  62% (36/58)\u001b[K\rremote: Compressing objects:  63% (37/58)\u001b[K\rremote: Compressing objects:  65% (38/58)\u001b[K\rremote: Compressing objects:  67% (39/58)\u001b[K\rremote: Compressing objects:  68% (40/58)\u001b[K\rremote: Compressing objects:  70% (41/58)\u001b[K\rremote: Compressing objects:  72% (42/58)\u001b[K\rremote: Compressing objects:  74% (43/58)\u001b[K\rremote: Compressing objects:  75% (44/58)\u001b[K\rremote: Compressing objects:  77% (45/58)\u001b[K\rremote: Compressing objects:  79% (46/58)\u001b[K\rremote: Compressing objects:  81% (47/58)\u001b[K\rremote: Compressing objects:  82% (48/58)\u001b[K\rremote: Compressing objects:  84% (49/58)\u001b[K\rremote: Compressing objects:  86% (50/58)\u001b[K\rremote: Compressing objects:  87% (51/58)\u001b[K\rremote: Compressing objects:  89% (52/58)\u001b[K\rremote: Compressing objects:  91% (53/58)\u001b[K\rremote: Compressing objects:  93% (54/58)\u001b[K\rremote: Compressing objects:  94% (55/58)\u001b[K\rremote: Compressing objects:  96% (56/58)\u001b[K\rremote: Compressing objects:  98% (57/58)\u001b[K\rremote: Compressing objects: 100% (58/58)\u001b[K\rremote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "Unpacking objects:   1% (1/79)   \rUnpacking objects:   2% (2/79)   \rUnpacking objects:   3% (3/79)   \rUnpacking objects:   5% (4/79)   \rUnpacking objects:   6% (5/79)   \rUnpacking objects:   7% (6/79)   \rUnpacking objects:   8% (7/79)   \rUnpacking objects:  10% (8/79)   \rUnpacking objects:  11% (9/79)   \rUnpacking objects:  12% (10/79)   \rUnpacking objects:  13% (11/79)   \rUnpacking objects:  15% (12/79)   \rUnpacking objects:  16% (13/79)   \rUnpacking objects:  17% (14/79)   \rUnpacking objects:  18% (15/79)   \rUnpacking objects:  20% (16/79)   \rUnpacking objects:  21% (17/79)   \rUnpacking objects:  22% (18/79)   \rUnpacking objects:  24% (19/79)   \rUnpacking objects:  25% (20/79)   \rUnpacking objects:  26% (21/79)   \rremote: Total 79 (delta 23), reused 50 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects:  27% (22/79)   \rUnpacking objects:  29% (23/79)   \rUnpacking objects:  30% (24/79)   \rUnpacking objects:  31% (25/79)   \rUnpacking objects:  32% (26/79)   \rUnpacking objects:  34% (27/79)   \rUnpacking objects:  35% (28/79)   \rUnpacking objects:  36% (29/79)   \rUnpacking objects:  37% (30/79)   \rUnpacking objects:  39% (31/79)   \rUnpacking objects:  40% (32/79)   \rUnpacking objects:  41% (33/79)   \rUnpacking objects:  43% (34/79)   \rUnpacking objects:  44% (35/79)   \rUnpacking objects:  45% (36/79)   \rUnpacking objects:  46% (37/79)   \rUnpacking objects:  48% (38/79)   \rUnpacking objects:  49% (39/79)   \rUnpacking objects:  50% (40/79)   \rUnpacking objects:  51% (41/79)   \rUnpacking objects:  53% (42/79)   \rUnpacking objects:  54% (43/79)   \rUnpacking objects:  55% (44/79)   \rUnpacking objects:  56% (45/79)   \rUnpacking objects:  58% (46/79)   \rUnpacking objects:  59% (47/79)   \rUnpacking objects:  60% (48/79)   \rUnpacking objects:  62% (49/79)   \rUnpacking objects:  63% (50/79)   \rUnpacking objects:  64% (51/79)   \rUnpacking objects:  65% (52/79)   \rUnpacking objects:  67% (53/79)   \rUnpacking objects:  68% (54/79)   \rUnpacking objects:  69% (55/79)   \rUnpacking objects:  70% (56/79)   \rUnpacking objects:  72% (57/79)   \rUnpacking objects:  73% (58/79)   \rUnpacking objects:  74% (59/79)   \rUnpacking objects:  75% (60/79)   \rUnpacking objects:  77% (61/79)   \rUnpacking objects:  78% (62/79)   \rUnpacking objects:  79% (63/79)   \rUnpacking objects:  81% (64/79)   \rUnpacking objects:  82% (65/79)   \rUnpacking objects:  83% (66/79)   \rUnpacking objects:  84% (67/79)   \rUnpacking objects:  86% (68/79)   \rUnpacking objects:  87% (69/79)   \rUnpacking objects:  88% (70/79)   \rUnpacking objects:  89% (71/79)   \rUnpacking objects:  91% (72/79)   \rUnpacking objects:  92% (73/79)   \rUnpacking objects:  93% (74/79)   \rUnpacking objects:  94% (75/79)   \rUnpacking objects:  96% (76/79)   \rUnpacking objects:  97% (77/79)   \rUnpacking objects:  98% (78/79)   \rUnpacking objects: 100% (79/79)   \rUnpacking objects: 100% (79/79), done.\n",
            "Submodule 'src/lookahead' (https://github.com/lonePatient/lookahead_pytorch) registered for path 'src/lookahead'\n",
            "Cloning into '/content/hasoc_code/src/lookahead'...\n",
            "remote: Enumerating objects: 68, done.        \n",
            "remote: Counting objects:   1% (1/68)        \rremote: Counting objects:   2% (2/68)        \rremote: Counting objects:   4% (3/68)        \rremote: Counting objects:   5% (4/68)        \rremote: Counting objects:   7% (5/68)        \rremote: Counting objects:   8% (6/68)        \rremote: Counting objects:  10% (7/68)        \rremote: Counting objects:  11% (8/68)        \rremote: Counting objects:  13% (9/68)        \rremote: Counting objects:  14% (10/68)        \rremote: Counting objects:  16% (11/68)        \rremote: Counting objects:  17% (12/68)        \rremote: Counting objects:  19% (13/68)        \rremote: Counting objects:  20% (14/68)        \rremote: Counting objects:  22% (15/68)        \rremote: Counting objects:  23% (16/68)        \rremote: Counting objects:  25% (17/68)        \rremote: Counting objects:  26% (18/68)        \rremote: Counting objects:  27% (19/68)        \rremote: Counting objects:  29% (20/68)        \rremote: Counting objects:  30% (21/68)        \rremote: Counting objects:  32% (22/68)        \rremote: Counting objects:  33% (23/68)        \rremote: Counting objects:  35% (24/68)        \rremote: Counting objects:  36% (25/68)        \rremote: Counting objects:  38% (26/68)        \rremote: Counting objects:  39% (27/68)        \rremote: Counting objects:  41% (28/68)        \rremote: Counting objects:  42% (29/68)        \rremote: Counting objects:  44% (30/68)        \rremote: Counting objects:  45% (31/68)        \rremote: Counting objects:  47% (32/68)        \rremote: Counting objects:  48% (33/68)        \rremote: Counting objects:  50% (34/68)        \rremote: Counting objects:  51% (35/68)        \rremote: Counting objects:  52% (36/68)        \rremote: Counting objects:  54% (37/68)        \rremote: Counting objects:  55% (38/68)        \rremote: Counting objects:  57% (39/68)        \rremote: Counting objects:  58% (40/68)        \rremote: Counting objects:  60% (41/68)        \rremote: Counting objects:  61% (42/68)        \rremote: Counting objects:  63% (43/68)        \rremote: Counting objects:  64% (44/68)        \rremote: Counting objects:  66% (45/68)        \rremote: Counting objects:  67% (46/68)        \rremote: Counting objects:  69% (47/68)        \rremote: Counting objects:  70% (48/68)        \rremote: Counting objects:  72% (49/68)        \rremote: Counting objects:  73% (50/68)        \rremote: Counting objects:  75% (51/68)        \rremote: Counting objects:  76% (52/68)        \rremote: Counting objects:  77% (53/68)        \rremote: Counting objects:  79% (54/68)        \rremote: Counting objects:  80% (55/68)        \rremote: Counting objects:  82% (56/68)        \rremote: Counting objects:  83% (57/68)        \rremote: Counting objects:  85% (58/68)        \rremote: Counting objects:  86% (59/68)        \rremote: Counting objects:  88% (60/68)        \rremote: Counting objects:  89% (61/68)        \rremote: Counting objects:  91% (62/68)        \rremote: Counting objects:  92% (63/68)        \rremote: Counting objects:  94% (64/68)        \rremote: Counting objects:  95% (65/68)        \rremote: Counting objects:  97% (66/68)        \rremote: Counting objects:  98% (67/68)        \rremote: Counting objects: 100% (68/68)        \rremote: Counting objects: 100% (68/68), done.        \n",
            "remote: Compressing objects:   1% (1/62)        \rremote: Compressing objects:   3% (2/62)        \rremote: Compressing objects:   4% (3/62)        \rremote: Compressing objects:   6% (4/62)        \rremote: Compressing objects:   8% (5/62)        \rremote: Compressing objects:   9% (6/62)        \rremote: Compressing objects:  11% (7/62)        \rremote: Compressing objects:  12% (8/62)        \rremote: Compressing objects:  14% (9/62)        \rremote: Compressing objects:  16% (10/62)        \rremote: Compressing objects:  17% (11/62)        \rremote: Compressing objects:  19% (12/62)        \rremote: Compressing objects:  20% (13/62)        \rremote: Compressing objects:  22% (14/62)        \rremote: Compressing objects:  24% (15/62)        \rremote: Compressing objects:  25% (16/62)        \rremote: Compressing objects:  27% (17/62)        \rremote: Compressing objects:  29% (18/62)        \rremote: Compressing objects:  30% (19/62)        \rremote: Compressing objects:  32% (20/62)        \rremote: Compressing objects:  33% (21/62)        \rremote: Compressing objects:  35% (22/62)        \rremote: Compressing objects:  37% (23/62)        \rremote: Compressing objects:  38% (24/62)        \rremote: Compressing objects:  40% (25/62)        \rremote: Compressing objects:  41% (26/62)        \rremote: Compressing objects:  43% (27/62)        \rremote: Compressing objects:  45% (28/62)        \rremote: Compressing objects:  46% (29/62)        \rremote: Compressing objects:  48% (30/62)        \rremote: Compressing objects:  50% (31/62)        \rremote: Compressing objects:  51% (32/62)        \rremote: Compressing objects:  53% (33/62)        \rremote: Compressing objects:  54% (34/62)        \rremote: Compressing objects:  56% (35/62)        \rremote: Compressing objects:  58% (36/62)        \rremote: Compressing objects:  59% (37/62)        \rremote: Compressing objects:  61% (38/62)        \rremote: Compressing objects:  62% (39/62)        \rremote: Compressing objects:  64% (40/62)        \rremote: Compressing objects:  66% (41/62)        \rremote: Compressing objects:  67% (42/62)        \rremote: Compressing objects:  69% (43/62)        \rremote: Compressing objects:  70% (44/62)        \rremote: Compressing objects:  72% (45/62)        \rremote: Compressing objects:  74% (46/62)        \rremote: Compressing objects:  75% (47/62)        \rremote: Compressing objects:  77% (48/62)        \rremote: Compressing objects:  79% (49/62)        \rremote: Compressing objects:  80% (50/62)        \rremote: Compressing objects:  82% (51/62)        \rremote: Compressing objects:  83% (52/62)        \rremote: Compressing objects:  85% (53/62)        \rremote: Compressing objects:  87% (54/62)        \rremote: Compressing objects:  88% (55/62)        \rremote: Compressing objects:  90% (56/62)        \rremote: Compressing objects:  91% (57/62)        \rremote: Compressing objects:  93% (58/62)        \rremote: Compressing objects:  95% (59/62)        \rremote: Compressing objects:  96% (60/62)        \rremote: Compressing objects:  98% (61/62)        \rremote: Compressing objects: 100% (62/62)        \rremote: Compressing objects: 100% (62/62), done.        \n",
            "remote: Total 68 (delta 31), reused 11 (delta 5), pack-reused 0        \n",
            "Submodule path 'src/lookahead': checked out '1055128057408fe8533ffa30654551a317f07f0a'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDBJAXod3ZZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy7TZAWZ6TAc",
        "colab_type": "text"
      },
      "source": [
        "### Install Apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8O3FSPb0AUF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73d85163-f335-40b6-bd21-b1b3bedf2621"
      },
      "source": [
        "%%writefile setup.sh\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLYwm8Cl4iw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iemxHSBz7SBb",
        "colab_type": "text"
      },
      "source": [
        "### Install tranformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIF3wwnW7Ecz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "ed2c3e86-1ac4-46d0-f9e7-35da2654c478"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/huggingface/transformers\n",
        "cd transformers\n",
        "pip install ."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (1.18.2)\n",
            "Collecting tokenizers==0.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (1.12.27)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "Collecting sacremoses\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (0.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (1.15.27)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers==2.6.0) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers==2.6.0) (2.8.1)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py): started\n",
            "  Building wheel for transformers (setup.py): finished with status 'done'\n",
            "  Created wheel for transformers: filename=transformers-2.6.0-cp36-none-any.whl size=537864 sha256=0db02219e4ef09c1a33d0f686dc27be789c7691088fe274c5df8a9fb3ad3f27d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t29zfou2/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=6b74c2145e9f4645fcd7ba474b728a2148e5a79a9103e790d9f2920412f4e6fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZwwEsY_UuZ6",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE7jfIRqUTtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "from typing import Callable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import notebook\n",
        "import importlib\n",
        "import pprint\n",
        "import nltk\n",
        "import datetime\n",
        "import os\n",
        "from argparse import Namespace\n",
        "import re\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXqXhgjIUy-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "#add the path to the src folder\n",
        "sys.path.append('/content/hasoc_code/src')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_rDeBsOUXKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils.general as general_utils\n",
        "import utils.data as data_utils\n",
        "import utils.transformer.data as transformer_data_utils\n",
        "import utils.transformer.general as transformer_general_utils\n",
        "general_utils.set_seed_everywhere() #set the seed for reproducibility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UfRWC0qUb-a",
        "colab_type": "code",
        "outputId": "9a194bc7-8420-4a7b-f4a9-a6c02e197532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "print(torch.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ukzh8WS_Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from radam import RAdam\n",
        "from lookahead import optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvLdf3pJ67m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjsqG7Z4VB3f",
        "colab_type": "text"
      },
      "source": [
        "# Set up the argspace/important_variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcFfJCICTeSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = Namespace(\n",
        "        #use cuda by default\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    \n",
        "        #set batch size and number of epochs\n",
        "        batch_size = 32,\n",
        "        num_epochs = 20,\n",
        "    \n",
        "        #set the learning rate\n",
        "        learning_rate = 0.0001,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22kr0FhCX1Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print('[c]olab or [l]ocal?[c/l] (Default: colab) ')\n",
        "# loc = (input() or 'c')\n",
        "loc = \"c\"\n",
        "loc = loc.lower()\n",
        "assert loc in ['c','colab','local','l']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSWgKzv8YzGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if loc in ['l','local']:\n",
        "    pass\n",
        "else : #for colab\n",
        "    #location of the train, dev and test csv\n",
        "    args.data_tsv = '/content/hasoc_code/data/english_dataset/english_dataset.tsv'\n",
        "    args.test_tsv = '/content/hasoc_code/data/english_dataset/hasoc2019_en_test-2919.tsv'\n",
        "\n",
        "    #directory to save our models at\n",
        "    args.directory = '/content/models/' \n",
        "    args.model_name = 'gpt2_eng_a.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFt_ff9uVgfV",
        "colab_type": "text"
      },
      "source": [
        "# Load the data tsv for Sub-task A\n",
        "Sub-task A focus on Hate speech and Offensive language identification offered for English, German, Hindi. Sub-task A is coarse-grained binary classification in which participating system are required to classify tweets into two class, namely: Hate and Offensive (HOF) and Non- Hate and offensive (NOT).\n",
        "\n",
        "- (NOT) Non Hate-Offensive - This post does not contain any Hate speech, offensive content.\n",
        "- (HOF) Hate and Offensive - This post contains Hate, offensive, and profane content.\n",
        "\n",
        "In our annotation, we label a post as HOF if it contains any form of non-acceptable language such as hate speech, aggression, profanity otherwise NOT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLNMib0Kawmg",
        "colab_type": "text"
      },
      "source": [
        "### Load the train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdNdJuwlVfyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hasoc_data_df = pd.read_csv(args.data_tsv, sep='\\t')\n",
        "hasoc_data_df_task_a = hasoc_data_df[['text','task_1']]\n",
        "hasoc_data_df_task_a.columns.values[1] = 'label'\n",
        "hasoc_data_df_task_a = hasoc_data_df_task_a[hasoc_data_df_task_a.label != 'NONE']\n",
        "del hasoc_data_df #free memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hawbE-56aL5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task_a_label_dict = {'NOT' :0, 'HOF': 1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2CP-06_Zm8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hasoc_data_df_task_a.label = hasoc_data_df_task_a.label.map(task_a_label_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8KxsUVSbXKw",
        "colab_type": "text"
      },
      "source": [
        "### Train set Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LYlFEX9aCmJ",
        "colab_type": "code",
        "outputId": "e0552e6d-72a5-44d0-ff92-3002eaa45be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "hasoc_data_df_task_a.sample(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3286</th>\n",
              "      <td>#Assange is not a #rapist  https://t.co/M4sfW7...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2876</th>\n",
              "      <td>#GandiNaaliAbuse | Where an MP says that he wi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>Candle light silent protest in MYSORE, by Myso...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>#ShameOnICC  1. ICC on Dhoni's gloves         ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>#ICC ...look at pak team...wht is going on.......</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "3286  #Assange is not a #rapist  https://t.co/M4sfW7...      0\n",
              "2876  #GandiNaaliAbuse | Where an MP says that he wi...      1\n",
              "2996  Candle light silent protest in MYSORE, by Myso...      0\n",
              "23    #ShameOnICC  1. ICC on Dhoni's gloves         ...      1\n",
              "1074  #ICC ...look at pak team...wht is going on.......      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP6lRcHfabEh",
        "colab_type": "code",
        "outputId": "695bd45c-1269-4661-ebd0-2fe5c5dc169d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "print(hasoc_data_df_task_a.label.value_counts())\n",
        "hasoc_data_df_task_a.label.value_counts().plot(kind='bar')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    3591\n",
            "1    2261\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f076a000630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sSm6p0o3_Cq",
        "colab_type": "text"
      },
      "source": [
        "### Split dataframe into train and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKFGEObIpEAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df = data_utils.Datasplitter.split_dataframe(hasoc_data_df_task_a, train_frac= 0.9, shuffle=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs_phT5RqeeN",
        "colab_type": "code",
        "outputId": "6cf8877c-f709-44d5-e3ae-7ef047859f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(data_df.split.value_counts())\n",
        "sum(data_df.label.value_counts()) == \\\n",
        "sum(data_df[data_df.split == 'train'].label.value_counts())\\\n",
        " + sum(data_df[data_df.split == 'val'].label.value_counts())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train    5267\n",
            "val       585\n",
            "Name: split, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Gwn6WizDaB",
        "colab_type": "code",
        "outputId": "bc489133-51c4-41e6-e163-a4b1462eb94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "hasoc_data_df_task_a.label.value_counts()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3591\n",
              "1    2261\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347OqySW6nOD",
        "colab_type": "text"
      },
      "source": [
        "## Create GPT2 Preprocessor\n",
        "Add special tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkhlygu1zHko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPT2Preprocessor():\n",
        "    \"\"\"Adds special tokens to the samples\"\"\"\n",
        "    def __init__(self,transformer_tokenizer,sentence_detector):\n",
        "        self.transformer_tokenizer = transformer_tokenizer\n",
        "        self.sentence_detector = sentence_detector\n",
        "        \n",
        "    def add_eos_tokens(self, text):\n",
        "        eos_token = ' ' + self.transformer_tokenizer.eos_token + ' '\n",
        "        sentences = self.sentence_detector.tokenize(text)\n",
        "        eos_added_text  = eos_token.join(sentences) + ' ' + self.transformer_tokenizer.eos_token\n",
        "        return eos_added_text "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_5PLkvd7fqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a52d9ab-0dd5-4cb6-f6be-526cfe6ce091"
      },
      "source": [
        " !python3 -c \"import nltk; nltk.download('punkt')\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujSA_8D6x9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\n",
        "    'gpt2'\n",
        ")\n",
        "punkt_sentence_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwUtLafp61ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2_preproc = GPT2Preprocessor(gpt2_tokenizer, punkt_sentence_detector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LESIUwL27z-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ceb5f213-c81d-4c54-e20c-00417d7dd23e"
      },
      "source": [
        "data_df['text'] = data_df['text'].map(gpt2_preproc.add_eos_tokens)\n",
        "print(data_df.columns)\n",
        "print(data_df.label.value_counts())\n",
        "print(data_df.split.value_counts())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['text', 'label', 'split'], dtype='object')\n",
            "0    3591\n",
            "1    2261\n",
            "Name: label, dtype: int64\n",
            "train    5267\n",
            "val       585\n",
            "Name: split, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuuOLpVO79dT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "1a3b0b65-b05f-4002-99ac-e8fc1f602bc1"
      },
      "source": [
        "with pd.option_context('display.max_colwidth', -1): \n",
        "    print(data_df[:10])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                                                                                                                                                                                                                                                                                  text  ...  split\n",
            "1840  BBMCH Balangir stand with NRSMCH  #DoctorsFightBack   #NRSMedicalCollege https://t.co/jfVN3DSfFJ <|endoftext|>                                                                                                                                                                                                                                    ...  train\n",
            "1544  More evidence piles in. <|endoftext|> Happy #JohnMcCainDay #TrumpIsATraitor #TrumpCrimeFamily #Oreo #DitchMitch2020 #arrestBARR  #Vets https://t.co/1R3hhH3mxW <|endoftext|>                                                                                                                                                                      ...  train\n",
            "2101  'Dhoni will always be my Captain' - 7th time so far Kohli has said these lines since Dhoni stepped down from Captaincy !!! <|endoftext|> !💗💗💗  @ChennaiIPL @imVkohli @msdhoni #IndiaWithDhoni #DhoniKeepTheGlove #DhoniKeepsTheGlove #ICCCricketWorldCup2019 https://t.co/u7Pfr9WBJA <|endoftext|>                                                ...  train\n",
            "1085  Hilarious because closely brushing the truth 😂🤣😂🤣😆😉  #BorisJohnsonShouldNotBePM   Boris Johnson dodging public debates to avoid inadvertently fathering a child during one - https://t.co/fkY6BG4mMD via @newsthump <|endoftext|>                                                                                                                 ...  train\n",
            "4993  @realDonaldTrump @foxandfriends Angela M. Thomas (@AngelaMThomas) Tweeted:  @realDonaldTrump #rapist #pedophile https://t.co/DKk8AWy5Uw <|endoftext|>                                                                                                                                                                                             ...  train\n",
            "2805  Plz support our savior... Request from AIIMS DELHI ....#DoctorsFightBack https://t.co/45Mh7xzISL <|endoftext|>                                                                                                                                                                                                                                    ...  train\n",
            "2174  The CM of the State, also the Health Minister, and such a ruthless response to the State Governer?? <|endoftext|> @MamataOfficial has completely lost the #WestBengal The situation is worse than what is actually looks from the videos/pictures at Social media &amp; News #DoctorsFightBack #SaveBengal https://t.co/4wz5uHDCUv <|endoftext|>  ...  train\n",
            "2482  @realDonaldTrump You wish. <|endoftext|> #FuckTrump <|endoftext|>                                                                                                                                                                                                                                                                                 ...  train\n",
            "3099  Rainbow flag at US embassy Rome #pride #fucktrump https://t.co/Svub8jzKW7 <|endoftext|>                                                                                                                                                                                                                                                           ...  train\n",
            "2581  Where's Wally!? <|endoftext|> #BorisJohnsonShouldNotBePM #WheresBoris #ToryLeadership <|endoftext|>                                                                                                                                                                                                                                               ...  train\n",
            "\n",
            "[10 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L769KdUr8A3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = transformer_data_utils.HateDataset(\n",
        "    data_df = data_df,\n",
        "    tokenizer = gpt2_tokenizer\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}